{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a13bf9f-e966-4bb4-9d27-789b6020140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4 x 800 Relay': 476.28, '110 Hurdles': 14.77, '100 Meters': 11.01, '1600 Meters': 256.7, '4 x 100 Relay': 42.44, '400 Meters': 49.07, '300 Hurdles': 39.35, '800 Meters': 115.21, '200 Meters': 22.21, '3200 Meters': 550.91, '4 x 400 Relay': 201.92, 'Discus': 1936.0, 'Shot Put': 676.0, 'Long Jump': 263.5, 'High Jump': 77.0, 'Pole Vault': 174.0}\n"
     ]
    }
   ],
   "source": [
    "from util.conversion_util import Conversion\n",
    "from util.db_util import Database\n",
    "import pandas as pd\n",
    "\n",
    "# girls\n",
    "xstandards = {\n",
    "    \"4 x 800 Relay\": \"9:23.63\",\n",
    "    \"100 Hurdles\": \"14.81\",          \n",
    "    \"100 Meters\": \"12.24\",\n",
    "    \"1600 Meters\": \"4:58.87\",\n",
    "    \"4 x 100 Relay\": \"48.41\",\n",
    "    \"400 Meters\": \"57.44\",\n",
    "    \"300 Hurdles\": \"45.44\",\n",
    "    \"800 Meters\": \"2:14.68\",\n",
    "    \"200 Meters\": \"25.34\",\n",
    "    \"3200 Meters\": \"10:47.57\",\n",
    "    \"4 x 400 Relay\": \"3:58.35\",\n",
    "    \"Discus\": \"127' 3\\\"\",\n",
    "    \"Shot Put\": \"42' 9.25\\\"\",\n",
    "    \"Long Jump\": \"18' 0.25\\\"\",\n",
    "    \"High Jump\": \"5' 4\\\"\",\n",
    "    \"Pole Vault\": \"11' 3\\\"\"\n",
    "}\n",
    "\n",
    "\n",
    "# boys\n",
    "standards = {\n",
    "    \"4 x 800 Relay\": \"7:56.28\",\n",
    "    \"110 Hurdles\": \"14.77\",\n",
    "    \"100 Meters\": \"11.01\",\n",
    "    \"1600 Meters\": \"4:16.70\",\n",
    "    \"4 x 100 Relay\": \"42.44\",\n",
    "    \"400 Meters\": \"49.07\",\n",
    "    \"300 Hurdles\": \"39.35\",\n",
    "    \"800 Meters\": \"1:55.21\",\n",
    "    \"200 Meters\": \"22.21\",\n",
    "    \"3200 Meters\": \"9:10.91\",\n",
    "    \"4 x 400 Relay\": \"3:21.92\",  \n",
    "    \"Discus\": \"161' 4\\\"\",\n",
    "    \"Shot Put\": \"56' 4\\\"\",\n",
    "    \"Long Jump\": \"21' 11.5\\\"\",\n",
    "    \"High Jump\": \"6' 5\\\"\",\n",
    "    \"Pole Vault\": \"14' 6\\\"\"\n",
    "}\n",
    "\n",
    "\n",
    "c = Conversion()\n",
    "\n",
    "for key, value in standards.items():\n",
    "    # if track event\n",
    "    if(key[0].isdigit()):\n",
    "        standards[key] = c.time_to_seconds(value)\n",
    "    else:\n",
    "        standards[key] = c.distance_to_inches(value)\n",
    "\n",
    "print(standards)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f13bacc-7992-4b0d-bb58-534da4c7d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 x 800 Relay    7:56.28\n",
      "110 Hurdles      14.77\n",
      "100 Meters       10.90\n",
      "1600 Meters      4:16.70\n",
      "4 x 100 Relay    42.44\n",
      "400 Meters       49.07\n",
      "300 Hurdles      39.35\n",
      "800 Meters       1:55.21\n",
      "200 Meters       22.09\n",
      "3200 Meters      9:10.91\n",
      "4 x 400 Relay    3:21.92\n",
      "Discus           161' 4\"\n",
      "Shot Put         56' 4.25\"\n",
      "Long Jump        21' 11.75\"\n",
      "High Jump        6' 5\"\n",
      "Pole Vault       14' 6\"\n"
     ]
    }
   ],
   "source": [
    "db = Database(\"db/Track.db\")\n",
    "c = Conversion()\n",
    "\n",
    "for key in standards:\n",
    "    res = db.get_state_standard(2025, \"Boys\", key)\n",
    "\n",
    "    if key[0].isdigit():     \n",
    "        print(f\"{key:<15}  {c.seconds_to_time(res)}\")\n",
    "    else:\n",
    "        print(f\"{key:<15}  {c.inches_to_distance(res)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55ae631a-ded4-43a3-a5d7-c97d4b3da1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "YEAR = 2025\n",
    "QUALIFIERS_TO_PROCESS = \"State\" # Regional or State\n",
    "GENDER_LIST = ['Boys'] # Girls and/or Boys\n",
    "\n",
    "# are we processing State or Regional qualifiers\n",
    "if QUALIFIERS_TO_PROCESS == \"State\":\n",
    "    MEET_TYPE = 'Regional'\n",
    "    CALLBACKS = 3\n",
    "else:\n",
    "    MEET_TYPE = 'Sectional'\n",
    "    CALLBACKS = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3919de6-0818-41c5-bf7d-f532a4e07543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual results\n",
    "athlete_df = db.get_all_athlete_results()\n",
    "athlete_df = athlete_df[(athlete_df['meet_type'] == MEET_TYPE) & (athlete_df['result_type'] == \"Final\") & (athlete_df['year'] == YEAR)].copy()\n",
    "athlete_df['place'] = athlete_df['place'].astype('Int64')\n",
    "athlete_df.loc[:, 'name'] = athlete_df['last'] + \", \" + athlete_df['first']\n",
    "athlete_df = athlete_df.rename(columns={'name': 'Name', 'grade': 'Grade', \"school_name\": \"School\", \"result\": \"Result\"})\n",
    "\n",
    "# get relay results\n",
    "relay_df = db.get_all_relay_results()\n",
    "relay_df = relay_df[(relay_df['meet_type'] == MEET_TYPE) & (relay_df['year'] == YEAR)]\n",
    "relay_df['place'] = relay_df['place'].astype('Int64')\n",
    "relay_df = relay_df.rename(columns={\"school_name\": \"School\", \"result\": \"Result\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f4353b7-35d1-4d04-8cc4-37eda12ea76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if MEET_TYPE == \"Sectional\":\n",
    "    meets = [(1,2,3,4),(5,6,7,8),(9,10,11,12),(13,14,15,16),(17,18,19,20),(21,22,23,24),(25,26,27,28),(29,30,31,32)]\n",
    "else:\n",
    "    meets = [(1,2,3,4,5,6,7,8)]\n",
    "\n",
    "# determine max field lengths to for printing formatting \n",
    "PADDING = 5\n",
    "SCHOOL_LEN = max(len(relay_df.loc[relay_df['School'].str.len().idxmax(), 'School']), len(athlete_df.loc[athlete_df['School'].str.len().idxmax(), 'School'])) + PADDING\n",
    "ATHLETE_LEN = len(athlete_df.loc[athlete_df['Name'].str.len().idxmax(), 'Name']) + PADDING\n",
    "RESULT_LEN = max(len(athlete_df.loc[athlete_df['Result'].str.len().idxmax(), 'Result']), len(relay_df.loc[relay_df['Result'].str.len().idxmax(), 'Result'])) + PADDING\n",
    "GRADE_LEN = 2 + PADDING\n",
    "PLACE_LEN = 1 + PADDING\n",
    "\n",
    "# iterate through all the meets\n",
    "for m in meets:\n",
    "\n",
    "    # iterate through all the genders\n",
    "    for g in GENDER_LIST:\n",
    "\n",
    "        meet_num = m[3]/4\n",
    "\n",
    "        if MEET_TYPE == \"Sectional\":\n",
    "            filename = g + \" Regional #\" + str(int(meet_num)) + \".txt\"\n",
    "        else:\n",
    "            filename = g + \" State.txt\"\n",
    "        \n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(filename[:-4] + \"\\n\") \n",
    "            file.write(\"This is an unofficial list of qualifiers. The list was generated by taking the top three finishers from each \" + MEET_TYPE + \", followed by the callbacks. An asterisk (*) next to an athlete's name indicates a callback. This list does not account for possible scratches that may occur after \" + MEET_TYPE + \"s.\\n\")\n",
    "        \n",
    "        # specify events and order to process events\n",
    "        events = [\"100 Meters\", \"200 Meters\", \"400 Meters\", \"800 Meters\", \"1600 Meters\", \"3200 Meters\", \"100 Hurdles\", \"300 Hurdles\", \"High Jump\", \"Long Jump\", \"Shot Put\", \"Discus\", \"Pole Vault\", \"4 x 100 Relay\", \"4 x 400 Relay\", \"4 x 800 Relay\"]      \n",
    "   \n",
    "        if g == \"Boys\":\n",
    "            events[6] = \"110 Hurdles\"\n",
    "        else:\n",
    "            events[6] = \"100 Hurdles\"\n",
    "\n",
    "        master_df = pd.DataFrame()\n",
    "        \n",
    "        # iterate through all the events\n",
    "        for e in events:\n",
    " \n",
    "            # set sort order and event type (Relay, Track, or Field)\n",
    "            if(e[0].isdigit()):\n",
    "                sort_ascending = True\n",
    "                \n",
    "                if \"Relay\" in e:\n",
    "                    event_type = \"Relay\"\n",
    "                else:\n",
    "                    event_type = \"Track\"\n",
    "            else:\n",
    "                sort_ascending = False\n",
    "                event_type = \"Field\"\n",
    "            \n",
    "            # set dataframes and columns based off individual or relay processing\n",
    "            if event_type == \"Relay\":\n",
    "                podium_df = relay_df[relay_df[\"place\"] <= 3]\n",
    "                other_df = relay_df[(relay_df[\"place\"] > 3)]\n",
    "                col_widths = {'School': SCHOOL_LEN, 'Result' : RESULT_LEN, 'place': PLACE_LEN, 'host': SCHOOL_LEN}\n",
    "                col_list = ['School', 'Result', 'place', 'host']\n",
    "            else:\n",
    "                podium_df = athlete_df[athlete_df[\"place\"] <= 3]\n",
    "                other_df = athlete_df[(athlete_df[\"place\"] > 3)]\n",
    "                col_widths = {'Name': ATHLETE_LEN, 'Grade': GRADE_LEN, 'School': SCHOOL_LEN, 'Result' : RESULT_LEN, 'place': PLACE_LEN, 'host' : SCHOOL_LEN }\n",
    "                col_list = ['Name', 'Grade', 'School', 'Result', 'place', 'host']\n",
    "            \n",
    "            # get top 3 place finishers and potential callbacks\n",
    "            top3_df = podium_df.query(\"gender == @g and event == @e and meet_num in @m\")\n",
    "\n",
    "            # event standard\n",
    "            standard = standards[e]\n",
    "            \n",
    "            # get any performances that were not in top 3 but were a state standard\n",
    "            if event_type == \"Field\":\n",
    "                state_standard_df = other_df.query(\"gender == @g and event == @e and meet_num in @m and result2 >= @standard\")\n",
    "                remaining_df = other_df.query(\"gender == @g and event == @e and meet_num in @m and result2 < @standard\")\n",
    "            else:\n",
    "                state_standard_df = other_df.query(\"gender == @g and event == @e and meet_num in @m and result2 <= @standard\")\n",
    "                remaining_df = other_df.query(\"gender == @g and event == @e and meet_num in @m and result2 > @standard\")\n",
    "\n",
    "            # mark the rows as advancing by STAN\n",
    "            state_standard_df.loc[:,'place'] = \"#\"\n",
    "            \n",
    "            # determine number of callback spots available \n",
    "            num_callbacks = max(CALLBACKS - len(state_standard_df), 0)\n",
    "\n",
    "            if num_callbacks > 0:\n",
    "                callback_df = remaining_df.query(\"gender == @g and event == @e and meet_num in @m\")\n",
    "                \n",
    "                callback_df.loc[:,'place'] = \"*\" \n",
    "                \n",
    "                # sort callbacks\n",
    "                sorted_callback_df = callback_df.sort_values(by='result2', ascending=sort_ascending)\n",
    "            \n",
    "                # process possible ties with callback\n",
    "                last_callback_result = sorted_callback_df.iloc[num_callbacks-1]['result2']\n",
    "\n",
    "                done = False\n",
    "                while(not done):\n",
    "                    current_result = sorted_callback_df.iloc[num_callbacks]['result2']\n",
    "\n",
    "                    # does the current result tie the last callback result?\n",
    "                    if current_result == last_callback_result: \n",
    "                        num_callbacks = num_callbacks + 1\n",
    "                    else:\n",
    "                        done = True                            \n",
    "\n",
    "            # put all qualifiers into a dataframe\n",
    "            if num_callbacks > 0:\n",
    "                qualifiers_df = pd.concat([top3_df, state_standard_df, sorted_callback_df.head(num_callbacks).copy()], ignore_index=True)\n",
    "            else:\n",
    "                qualifiers_df = pd.concat([top3_df, state_standard_df], ignore_index=True)\n",
    "  \n",
    "            # sort qualifiers\n",
    "            sorted_qualifiers_df = qualifiers_df.sort_values(by='result2', ascending=sort_ascending)\n",
    "            sorted_qualifiers_df['host'] = sorted_qualifiers_df['host'].astype(str) + \" (\" + sorted_qualifiers_df['place'].astype(str) + \")\"\n",
    "            \n",
    "            # add this event qualifiers to the master dataframe of all the qualifiers\n",
    "            master_df = pd.concat([master_df, sorted_qualifiers_df], ignore_index=True)\n",
    "\n",
    "            # append qualifiers to the file\n",
    "            with open(filename, \"a\") as file:\n",
    "                file.write(\"\\n\")\n",
    "                file.write(\"*** Event \" + e + \" ***\\n\")\n",
    "                    \n",
    "                # format and print each row\n",
    "                header = \"\".join(f\"{col:<{col_widths[col]}}\" for col in col_list)\n",
    "                file.write(header + \"\\n\")\n",
    "                file.write(\"-\" * len(header) + \"\\n\")\n",
    "                    \n",
    "                for _, row in sorted_qualifiers_df.iterrows():\n",
    "                    line = \"\".join(f\"{str(row[col]):<{col_widths[col]}}\" for col in col_list)\n",
    "                    file.write(line + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aaf4580-7639-44b4-ae93-d7fa651a40cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franklin Central: 39\n",
      "Lawrence North: 37\n",
      "Avon: 36\n",
      "Warsaw Community: 36\n",
      "Merrillville: 32\n",
      "North Central (Indianapolis): 31\n",
      "Indianapolis Bishop Chatard: 29\n",
      "Bloomington North: 29\n",
      "Chesterton: 21\n",
      "Center Grove: 20\n",
      "Mt. Vernon (Fortville): 18\n",
      "Westview: 18\n",
      "Brownsburg: 18\n",
      "Churubusco: 17\n",
      "Columbus North: 16\n",
      "Concord: 15\n",
      "Greenwood Community: 14\n",
      "Fishers: 13\n",
      "Noblesville: 12\n",
      "Evansville North: 10\n",
      "Homestead: 10\n",
      "Northridge: 10\n",
      "Mishawaka: 10\n",
      "Crown Point: 10\n",
      "Lawrence Central: 9\n",
      "Brebeuf Jesuit Preparatory: 9\n",
      "Bloomington South: 8\n",
      "Warren Central: 8\n",
      "Floyd Central: 8\n",
      "Indianapolis Cathedral: 7\n",
      "Tri-West Hendricks: 7\n",
      "Elkhart: 7\n",
      "Ben Davis: 7\n",
      "Andrean: 7\n",
      "Batesville: 7\n",
      "Heritage Christian: 7\n",
      "Carmel: 6\n",
      "Jennings County: 6\n",
      "Springs Valley: 6\n",
      "New Haven: 6\n",
      "Owen Valley: 6\n",
      "Southport: 6\n",
      "Henryville: 6\n",
      "Westfield: 6\n",
      "LaPorte: 6\n",
      "NorthWood: 5\n",
      "Charlestown: 5\n",
      "Fort Wayne Snider: 5\n",
      "Lakewood Park Christian: 5\n",
      "Plainfield: 5\n",
      "West Noble: 5\n",
      "Salem: 5\n",
      "Lebanon: 5\n",
      "Wabash: 4\n",
      "Evansville Mater Dei: 4\n",
      "Fort Wayne Bishop Luers: 4\n",
      "Cascade: 4\n",
      "Jeffersonville: 3\n",
      "New Palestine: 3\n",
      "Fort Wayne Northrop: 3\n",
      "Elkhart Christian Academy: 3\n",
      "Silver Creek: 3\n",
      "Hamilton Southeastern: 3\n",
      "Leo: 3\n",
      "Riverside: 2\n",
      "Richmond: 2\n",
      "Whiteland Community: 2\n",
      "Portage: 1\n",
      "Delta: 1\n",
      "Greenfield-Central: 1\n",
      "Harrison (West Lafayette): 1\n",
      "Fairfield: 1\n",
      "Muncie Central: 1\n",
      "Indianapolis Cardinal Ritter: 1\n"
     ]
    }
   ],
   "source": [
    "master_df\n",
    "\n",
    "place_values = {\n",
    "    1: 10,\n",
    "    2: 8,\n",
    "    3: 7,\n",
    "    4: 6,\n",
    "    5: 5,\n",
    "    6: 4,\n",
    "    7: 3,\n",
    "    8: 2,\n",
    "    9: 1\n",
    "}\n",
    "\n",
    "results_dict = {}\n",
    "place = 1\n",
    "current_event = \"\"\n",
    "\n",
    "for index, row in master_df.iterrows():\n",
    "    school = row['School']\n",
    "    event = row['event']\n",
    "    \n",
    "    if current_event != event:\n",
    "        current_event = event\n",
    "        place = 1\n",
    "    else:\n",
    "        place = place + 1\n",
    "    \n",
    "    #print(f\"Row {index}: School={row['School']}, {row['event']}\")\n",
    "\n",
    "    if place < 10:\n",
    "        if school in results_dict:\n",
    "            results_dict[school] = results_dict[school] + place_values[place]\n",
    "        else:\n",
    "            results_dict[school] = place_values[place]\n",
    "\n",
    "sorted_dict = dict(sorted(results_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "for key, value in sorted_dict.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a457942-14e4-4e86-baf8-dd99bd2f4038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
